{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "# Train\n",
        "\n",
        "Training various models, following this [Kaggle guide](https://www.kaggle.com/code/merturper/breast-cancer-outliers-pca-nca/notebook#Train-Test-Split-&-StandardScaler). Pushing results to our \"Wisconsin BCa\" experiment in MLFlow.\n",
        "\n",
        "Note that the `train` folder contains code to package and train the model on the cloud, while this is just playing around."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "## Read Data \n",
        "\n",
        "Read both boxplot and lof preprocessed data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1683843722625
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
        "from sklearn.neighbors import KNeighborsClassifier, NeighborhoodComponentsAnalysis, LocalOutlierFactor\n",
        "from sklearn.ensemble import VotingClassifier\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "import mlflow\n",
        "import mlflow.sklearn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1683843736085
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "# get a handle of the data asset and print the URI\n",
        "data_boxplot = './data/cleaned-wisconsin-boxplot.parquet'\n",
        "data_lof = './data/cleaned-wisconsin-lof.parquet'\n",
        "\n",
        "df_boxplot = pd.read_parquet(data_boxplot)\n",
        "df_lof = pd.read_parquet(data_boxplot)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Setup MLFLow\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from azure.ai.ml import MLClient\n",
        "from azure.identity import DefaultAzureCredential\n",
        "\n",
        "ml_client = MLClient.from_config(credential=DefaultAzureCredential())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "mlflow_tracking_uri = ml_client.workspaces.get(ml_client.workspace_name).mlflow_tracking_uri\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "## Define"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1683843716154
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "def split_and_scale(df):\n",
        "    y = df[\"diagnosis_01\"]\n",
        "    X = df.drop([\"diagnosis_01\"],axis=1)\n",
        "\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.30)\n",
        "\n",
        "    scaler = StandardScaler()\n",
        "    X_train = scaler.fit_transform(X_train)\n",
        "    X_test = scaler.transform(X_test)\n",
        "\n",
        "    return X_train, X_test, y_train, y_test\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1683832647413
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "def train_logistic(X_train, X_test, y_train, y_test):\n",
        "    log_reg = LogisticRegression()\n",
        "    log_reg.fit(X_train, y_train)\n",
        "    # model predictions\n",
        "    y_pred = log_reg.predict(X_test)\n",
        "    mlflow.log_metrics({\n",
        "        'trainScore': accuracy_score(y_train, log_reg.predict(X_train)),\n",
        "        'testScore': accuracy_score(y_test, log_reg.predict(X_test))\n",
        "    })\n",
        "    mlflow.log_dict(np.array(confusion_matrix(y_test, y_pred)).tolist(), artifact_file='confusion_matrix.json')\n",
        "    mlflow.log_dict(classification_report(y_test, y_pred), 'classification_report.json')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1683832647475
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "def train_knn(X_train, X_test, y_train, y_test):\n",
        "    knn = KNeighborsClassifier(n_neighbors = 3)\n",
        "    knn.fit(X_train, y_train)\n",
        "    y_pred = knn.predict(X_test)\n",
        "    mlflow.log_metrics({\n",
        "        'trainScore': accuracy_score(y_train, knn.predict(X_train)),\n",
        "        'testScore': accuracy_score(y_test, knn.predict(X_test))\n",
        "    })\n",
        "    mlflow.log_dict(np.array(confusion_matrix(y_test, y_pred)).tolist(), artifact_file='confusion_matrix.json')\n",
        "    mlflow.log_dict(classification_report(y_test, y_pred), 'classification_report.json')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1683832647577
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "def train_svc(X_train, X_test, y_train, y_test):\n",
        "    svc = SVC()\n",
        "    svc.fit(X_train, y_train)\n",
        "    # model predictions \n",
        "    y_pred = svc.predict(X_test)\n",
        "    mlflow.log_metrics({\n",
        "        'trainScore': accuracy_score(y_train, svc.predict(X_train)),\n",
        "        'testScore': accuracy_score(y_test, svc.predict(X_test))\n",
        "    })\n",
        "    mlflow.log_dict(np.array(confusion_matrix(y_test, y_pred)).tolist(), artifact_file='confusion_matrix.json')\n",
        "    mlflow.log_dict(classification_report(y_test, y_pred), 'classification_report.json')"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "## Run"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1683832650494
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "# set name for logging\n",
        "mlflow.set_experiment(\"Wisconsin BCa Experiment local\")\n",
        "mlflow.autolog()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1683833368990
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "# random helper function\n",
        "# https://stackoverflow.com/a/11146645\n",
        "def cartesian_product(x, y):\n",
        "    return [(x0, y0) for x0 in x for y0 in y]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1683834086157
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "with mlflow.start_run():\n",
        "    dfs = [(df_boxplot, 'boxplot'), (df_lof, 'lof')]\n",
        "    trains = [(train_knn, 'knn'), (train_logistic, 'logistic'), (train_svc, 'svc')]\n",
        "\n",
        "    mlflow.log_param(\"parent\", \"yes\")\n",
        "    for (df, df_name), (train, train_name) in [(x0, y0) for x0 in dfs for y0 in trains]:\n",
        "        with mlflow.start_run(run_name=f'{df_name}-outlier-with-{train_name}', nested=True):\n",
        "            mlflow.set_tag('outlier_func', df_name)\n",
        "            X_train, X_test, y_train, y_test = split_and_scale(df)\n",
        "            train(X_train, X_test, y_train, y_test)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Viewing the models\n",
        "\n",
        "See the models by running `mlflow ui`. I might connect this with azure..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1683843884205
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = split_and_scale(df_lof)\n",
        "print(len(X_test[0]))\n",
        "list(df_lof.columns[:-1])"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "## Summary\n",
        "\n",
        "The Kaggle guy says that SVC gives the best results. I'm going to just use SVC and deploy it, comparing results is a bit weird on Azure somehow."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "##"
      ]
    }
  ],
  "metadata": {
    "kernel_info": {
      "name": "python310-sdkv2"
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    },
    "microsoft": {
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      },
      "ms_spell_check": {
        "ms_spell_check_language": "en"
      }
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}

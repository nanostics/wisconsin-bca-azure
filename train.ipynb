{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Train\n",
        "\n",
        "Training various models, following this [Kaggle guide](https://www.kaggle.com/code/merturper/breast-cancer-outliers-pca-nca/notebook#Train-Test-Split-&-StandardScaler). Pushing results to our \"Wisconsin BCa\" experiment.\n",
        "\n",
        "Using MLFlow library to log our results: https://learn.microsoft.com/en-us/azure/machine-learning/tutorial-train-model?view=azureml-api-2"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setup\n",
        "\n",
        "Note I am not creating a Compute cluster because we don't have enough quota, plus it's unnecessary for such a small dataset."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azure.ai.ml import MLClient\n",
        "from azure.identity import DefaultAzureCredential\n",
        "\n",
        "# authenticate\n",
        "credential = DefaultAzureCredential()\n",
        "\n",
        "# Get a handle to the workspace\n",
        "ml_client = MLClient(\n",
        "    credential=credential,\n",
        "    subscription_id=\"1b1ae7cf-df24-428b-8bb9-e4dd07869ac9\",\n",
        "    resource_group_name=\"SummerProjects2023\",\n",
        "    workspace_name=\"Nanostics_ML_Workspace\",\n",
        ")"
      ],
      "outputs": [],
      "execution_count": 7,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1683843730451
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Read Data \n",
        "\n",
        "Read both boxplot and lof preprocessed data"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
        "from sklearn.neighbors import KNeighborsClassifier, NeighborhoodComponentsAnalysis, LocalOutlierFactor\n",
        "from sklearn.ensemble import VotingClassifier\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC"
      ],
      "outputs": [],
      "execution_count": 4,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1683843722625
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# get a handle of the data asset and print the URI\n",
        "data_boxplot = ml_client.data.get(name=\"wisconsin-bca\", version='2-boxplot')\n",
        "data_lof = ml_client.data.get(name=\"wisconsin-bca\", version='2-lof')\n",
        "print(f\"Data asset URI (boxplot): {data_boxplot.path}\")\n",
        "print(f\"Data asset URI (log): {data_lof.path}\")\n",
        "\n",
        "\n",
        "df_boxplot = pd.read_parquet(data_boxplot.path)\n",
        "df_lof = pd.read_parquet(data_boxplot.path)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Data asset URI (boxplot): azureml://subscriptions/1b1ae7cf-df24-428b-8bb9-e4dd07869ac9/resourcegroups/SummerProjects2023/workspaces/Nanostics_ML_Workspace/datastores/workspaceblobstore/paths/LocalUpload/87247cc674f58dd015f9a173b014e577/cleaned-wisconsin-bca.parquet\nData asset URI (log): azureml://subscriptions/1b1ae7cf-df24-428b-8bb9-e4dd07869ac9/resourcegroups/SummerProjects2023/workspaces/Nanostics_ML_Workspace/datastores/workspaceblobstore/paths/LocalUpload/6ad44bced7ba2bd6022a77c7f4ace95b/cleaned-wisconsin-bca-lof.parquet\n"
        }
      ],
      "execution_count": 8,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1683843736085
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Define"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def split_and_scale(df):\n",
        "    y = df[\"diagnosis_01\"]\n",
        "    X = df.drop([\"diagnosis_01\"],axis=1)\n",
        "\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.30)\n",
        "\n",
        "    scaler = StandardScaler()\n",
        "    X_train = scaler.fit_transform(X_train)\n",
        "    X_test = scaler.transform(X_test)\n",
        "\n",
        "    return X_train, X_test, y_train, y_test\n",
        "    "
      ],
      "outputs": [],
      "execution_count": 2,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1683843716154
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_logistic(X_train, X_test, y_train, y_test):\n",
        "    log_reg = LogisticRegression()\n",
        "    log_reg.fit(X_train, y_train)\n",
        "    # model predictions\n",
        "    y_pred = log_reg.predict(X_test)\n",
        "    print(\"*****LogisticRegression******\\n\")\n",
        "    print(\"Train score:\")\n",
        "    print(accuracy_score(y_train, log_reg.predict(X_train)))\n",
        "    print(\"Test score:\")\n",
        "    log_reg_acc = accuracy_score(y_test, log_reg.predict(X_test))\n",
        "    print(log_reg_acc)\n",
        "    # confusion matrix\n",
        "    print(\"Accuracy Score:\")\n",
        "    print(confusion_matrix(y_test, y_pred))\n",
        "    # classification report\n",
        "    print(classification_report(y_test, y_pred))"
      ],
      "outputs": [],
      "execution_count": 5,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1683832647413
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_knn(X_train, X_test, y_train, y_test):\n",
        "    knn = KNeighborsClassifier(n_neighbors = 3)\n",
        "    knn.fit(X_train, y_train)\n",
        "    y_pred = knn.predict(X_test)\n",
        "    print(\"******KNeighborsClassifier******\\n\")\n",
        "    # accuracy score\n",
        "    print(\"Train score:\")\n",
        "    print(accuracy_score(y_train, knn.predict(X_train)))\n",
        "    print(\"Test score:\")\n",
        "    knn_acc = accuracy_score(y_test, knn.predict(X_test))\n",
        "    print(knn_acc)\n",
        "    # confusion matrix\n",
        "    print(\"Accuracy Score:\")\n",
        "    print(confusion_matrix(y_test, y_pred))\n",
        "    # classification report\n",
        "    print(classification_report(y_test, y_pred))"
      ],
      "outputs": [],
      "execution_count": 6,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1683832647475
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_svc(X_train, X_test, y_train, y_test):\n",
        "    svc = SVC()\n",
        "    svc.fit(X_train, y_train)\n",
        "    # model predictions \n",
        "    y_pred = svc.predict(X_test)\n",
        "    print(\"******Support Vector Classifier******\\n\")\n",
        "    # accuracy score\n",
        "    print(\"Train score:\")\n",
        "    print(accuracy_score(y_train, svc.predict(X_train)))\n",
        "    print(\"Test score:\")\n",
        "    svc_acc = accuracy_score(y_test, svc.predict(X_test))\n",
        "    print(svc_acc)\n",
        "    # confusion matrix\n",
        "    print(\"Accuracy Score:\")\n",
        "    print(confusion_matrix(y_test, y_pred))\n",
        "    # classification report\n",
        "    print(classification_report(y_test, y_pred))"
      ],
      "outputs": [],
      "execution_count": 7,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1683832647577
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Run"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import mlflow\n",
        "import mlflow.sklearn\n",
        "\n",
        "# set name for logging\n",
        "mlflow.set_experiment(\"Wisconsin BCa Experiment 1\")\n",
        "# enable autologging with MLflow\n",
        "mlflow.sklearn.autolog()"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "2023/05/11 19:17:28 WARNING mlflow.utils.autologging_utils: You are using an unsupported version of sklearn. If you encounter errors during autologging, try upgrading / downgrading sklearn to a supported version, or try upgrading MLflow.\n"
        }
      ],
      "execution_count": 8,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1683832650494
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy\n",
        "# random helper function\n",
        "# https://stackoverflow.com/a/11146645\n",
        "def cartesian_product(x, y):\n",
        "    return [(x0, y0) for x0 in x for y0 in y]"
      ],
      "outputs": [],
      "execution_count": 12,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1683833368990
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with mlflow.start_run():\n",
        "    dfs = [(df_boxplot, 'boxplot'), (df_lof, 'lof')]\n",
        "    trains = [(train_knn, 'knn'), (train_logistic, 'logistic'), (train_svc, 'svc')]\n",
        "\n",
        "    mlflow.log_param(\"parent\", \"yes\")\n",
        "    for (df, df_name), (train, train_name) in [(x0, y0) for x0 in dfs for y0 in trains]:\n",
        "        with mlflow.start_run(run_name=f'{df_name}-outlier-with-{train_name}', nested=True):\n",
        "            X_train, X_test, y_train, y_test = split_and_scale(df)\n",
        "            train(X_train, X_test, y_train, y_test)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "******KNeighborsClassifier******\n\nTrain score:\n0.9771573604060914\nTest score:\n0.9526627218934911\nAccuracy Score:\n[[94  3]\n [ 5 67]]\n              precision    recall  f1-score   support\n\n           0       0.95      0.97      0.96        97\n           1       0.96      0.93      0.94        72\n\n    accuracy                           0.95       169\n   macro avg       0.95      0.95      0.95       169\nweighted avg       0.95      0.95      0.95       169\n\n*****LogisticRegression******\n\nTrain score:\n0.9898477157360406\nTest score:\n0.9704142011834319\nAccuracy Score:\n[[97  0]\n [ 5 67]]\n              precision    recall  f1-score   support\n\n           0       0.95      1.00      0.97        97\n           1       1.00      0.93      0.96        72\n\n    accuracy                           0.97       169\n   macro avg       0.98      0.97      0.97       169\nweighted avg       0.97      0.97      0.97       169\n\n******Support Vector Classifier******\n\nTrain score:\n0.9822335025380711\nTest score:\n0.9822485207100592\nAccuracy Score:\n[[97  0]\n [ 3 69]]\n              precision    recall  f1-score   support\n\n           0       0.97      1.00      0.98        97\n           1       1.00      0.96      0.98        72\n\n    accuracy                           0.98       169\n   macro avg       0.98      0.98      0.98       169\nweighted avg       0.98      0.98      0.98       169\n\n******KNeighborsClassifier******\n\nTrain score:\n0.9771573604060914\nTest score:\n0.9526627218934911\nAccuracy Score:\n[[94  3]\n [ 5 67]]\n              precision    recall  f1-score   support\n\n           0       0.95      0.97      0.96        97\n           1       0.96      0.93      0.94        72\n\n    accuracy                           0.95       169\n   macro avg       0.95      0.95      0.95       169\nweighted avg       0.95      0.95      0.95       169\n\n*****LogisticRegression******\n\nTrain score:\n0.9898477157360406\nTest score:\n0.9704142011834319\nAccuracy Score:\n[[97  0]\n [ 5 67]]\n              precision    recall  f1-score   support\n\n           0       0.95      1.00      0.97        97\n           1       1.00      0.93      0.96        72\n\n    accuracy                           0.97       169\n   macro avg       0.98      0.97      0.97       169\nweighted avg       0.97      0.97      0.97       169\n\n******Support Vector Classifier******\n\nTrain score:\n0.9822335025380711\nTest score:\n0.9822485207100592\nAccuracy Score:\n[[97  0]\n [ 3 69]]\n              precision    recall  f1-score   support\n\n           0       0.97      1.00      0.98        97\n           1       1.00      0.96      0.98        72\n\n    accuracy                           0.98       169\n   macro avg       0.98      0.98      0.98       169\nweighted avg       0.98      0.98      0.98       169\n\n"
        }
      ],
      "execution_count": 34,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1683834086157
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = split_and_scale(df_lof)\n",
        "print(len(X_test[0]))\n",
        "list(df_lof.columns[:-1])"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "26\n"
        },
        {
          "output_type": "execute_result",
          "execution_count": 17,
          "data": {
            "text/plain": "['texture_mean',\n 'smoothness_mean',\n 'compactness_mean',\n 'concavity_mean',\n 'concave points_mean',\n 'symmetry_mean',\n 'fractal_dimension_mean',\n 'radius_se',\n 'texture_se',\n 'perimeter_se',\n 'area_se',\n 'smoothness_se',\n 'compactness_se',\n 'concavity_se',\n 'concave points_se',\n 'symmetry_se',\n 'fractal_dimension_se',\n 'texture_worst',\n 'perimeter_worst',\n 'area_worst',\n 'smoothness_worst',\n 'compactness_worst',\n 'concavity_worst',\n 'concave points_worst',\n 'symmetry_worst',\n 'fractal_dimension_worst']"
          },
          "metadata": {}
        }
      ],
      "execution_count": 17,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1683843884205
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Summary\n",
        "\n",
        "The Kaggle guy says that SVC gives the best results. I'm going to just use SVC and deploy it, comparing results is a bit weird on Azure somehow."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python310-sdkv2",
      "language": "python",
      "display_name": "Python 3.10 - SDK v2"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.10",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "microsoft": {
      "ms_spell_check": {
        "ms_spell_check_language": "en"
      },
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      }
    },
    "kernel_info": {
      "name": "python310-sdkv2"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}